Claude 3.5 Sonnet on 2024-12-25

> I am working on changing the input of a Python program I wrote. The original program is taking a series of complex Tiff images to calculate the amplitude dispersion index and saves it. Here is the original code

<<<
import numpy as np
import rasterio
from pathlib import Path
from typing import Dict, Union
import logging


def calculate_amplitude_dispersion(
        input_directory: str,
        output_file: str,
        ps_threshold: float = 0.25
) -> Dict[str, Union[float, int]]:
    """
    Calculate amplitude dispersion index from a stack of complex SAR images.

    Parameters:
    -----------
    input_directory : str
        Path to directory containing coregistered complex SAR images in GeoTIFF format
    output_file : str
        Path where the output amplitude dispersion GeoTIFF will be saved
    ps_threshold : float
        Threshold for PS candidate selection (default: 0.25)

    Returns:
    --------
    Dict containing statistics about the amplitude dispersion calculation
    """

    # Setup logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    # Get list of input files
    image_files = list(Path(input_directory).glob('*.tiff'))
    if not image_files:
        raise ValueError(f"No TIFF files found in {input_directory}")

    logger.info(f"Found {len(image_files)} images to process")

    # Read metadata from first image
    with rasterio.open(image_files[0]) as src:
        profile = src.profile
        shape = src.shape

    # Initialize arrays for calculations
    sum_amplitude = np.zeros(shape, dtype=np.float32)
    sum_squared_amplitude = np.zeros(shape, dtype=np.float32)
    n_images = 0

    # Process each image
    logger.info("Processing images...")
    for img_file in image_files:
        with rasterio.open(img_file) as src:
            # Read complex data
            complex_data = src.read(1).astype(np.complex64)

            # Calculate amplitude
            amplitude = np.abs(complex_data)

            # Update running sums
            sum_amplitude += amplitude
            sum_squared_amplitude += amplitude * amplitude
            n_images += 1

        logger.info(f"Processed {n_images}/{len(image_files)} images")

    # Calculate statistics
    mean_amplitude = sum_amplitude / n_images

    # Calculate variance using computational formula
    variance = (sum_squared_amplitude / n_images) - (mean_amplitude * mean_amplitude)
    # Ensure non-negative variance due to numerical precision
    variance = np.maximum(variance, 0)
    std_amplitude = np.sqrt(variance)

    # Calculate amplitude dispersion
    amplitude_dispersion = np.zeros_like(mean_amplitude)
    valid_pixels = mean_amplitude > 0
    amplitude_dispersion[valid_pixels] = std_amplitude[valid_pixels] / mean_amplitude[valid_pixels]

    # Set invalid pixels to NaN
    amplitude_dispersion[~valid_pixels] = np.nan

    # Update profile for output
    profile.update({
        'dtype': 'float32',
        'count': 1,
        'nodata': np.nan
    })

    # Write output
    logger.info("Writing output file...")
    with rasterio.open(output_file, 'w', **profile) as dst:
        dst.write(amplitude_dispersion.astype(np.float32), 1)

    # Calculate statistics
    valid_da = amplitude_dispersion[~np.isnan(amplitude_dispersion)]
    ps_candidates = np.sum(valid_da < ps_threshold)

    stats = {
        'min_da': float(np.nanmin(amplitude_dispersion)),
        'max_da': float(np.nanmax(amplitude_dispersion)),
        'mean_da': float(np.nanmean(amplitude_dispersion)),
        'median_da': float(np.nanmedian(amplitude_dispersion)),
        'ps_candidates': int(ps_candidates),
        'total_valid_pixels': int(np.sum(valid_pixels)),
        'processed_images': n_images
    }

    logger.info("Processing completed successfully")
    logger.info(f"Found {ps_candidates} PS candidates (DA < {ps_threshold})")

    return stats


if __name__ == "__main__":
    # Example usage
    #input_dir = "./sar_images"  # Directory containing complex SAR images
    #output_file = "./amplitude_dispersion.tif"  # Output file path

    input_dir = "/home/timo/Data/LasVegasDesc/resampled"
    output_file = "/home/timo/Data/LasVegasDesc/amplitude_dispersion.tif"

    try:
        stats = calculate_amplitude_dispersion(input_dir, output_file)
        print("Statistics:", stats)
    except Exception as e:
        logging.error(f"Error during processing: {str(e)}")
>>>

Now, I want to use the BEAM-DIMAP output from ESA's Snap tool as input. The dim file contains all bands necessary to calculate the amplitude dispersion index. We need to go through the bands in the dim file and select the band where the name starts with 'Intensity'. This is our input. Unfortunately, the memory is limited, so we need to o this processing line by line, reading each line of the bands separetly and calculate the amplitude dispersion for each pixel. Below I have some example for using esa_snappy to do access the BEAM-DIMAP file.

<<<

import sys
import numpy as np
sys.path.append('/home/timo/.snap/snap-python')
import esa_snappy

# Read the .dim file
product = esa_snappy.ProductIO.readProduct('/home/timo/Data/LVS1_snap/deburst/S1A_IW_SLC__1SDV_20230702T134404_20230702T134432_049245_05EBEA_A4DF_Orb_Stack_esd_deb.dim')

# Get the width and height
width = product.getSceneRasterWidth()
height = product.getSceneRasterHeight()
names = product.getBandNames()
for name in names:
    print(name)

>>>

Please create the new version reading from esa_snappy instead of the complex tiff files. Please only show me the code and do not run it in the code interpreter.


I'll help you modify the code to work with BEAM-DIMAP files using esa_snappy, processing the data line by line to manage memory usage. Here's the modified version:

```python
import numpy as np
from pathlib import Path
from typing import Dict, Union
import logging
import sys
import esa_snappy
import rasterio

def calculate_amplitude_dispersion_snap(
        input_dim_file: str,
        output_file: str,
        ps_threshold: float = 0.25
) -> Dict[str, Union[float, int]]:
    """
    Calculate amplitude dispersion index from a BEAM-DIMAP file containing intensity bands.

    Parameters:
    -----------
    input_dim_file : str
        Path to the input BEAM-DIMAP (.dim) file
    output_file : str
        Path where the output amplitude dispersion GeoTIFF will be saved
    ps_threshold : float
        Threshold for PS candidate selection (default: 0.25)

    Returns:
    --------
    Dict containing statistics about the amplitude dispersion calculation
    """
    # Setup logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    # Read the product
    logger.info(f"Reading product: {input_dim_file}")
    product = esa_snappy.ProductIO.readProduct(input_dim_file)

    # Get dimensions
    width = product.getSceneRasterWidth()
    height = product.getSceneRasterHeight()

    # Get intensity bands
    band_names = product.getBandNames()
    intensity_bands = [name for name in band_names if name.startswith('Intensity')]
    
    if not intensity_bands:
        raise ValueError("No intensity bands found in the product")

    n_images = len(intensity_bands)
    logger.info(f"Found {n_images} intensity bands to process")

    # Get geotransform and projection information from the first band
    first_band = product.getBand(intensity_bands[0])
    
    # Create output profile for rasterio
    profile = {
        'driver': 'GTiff',
        'height': height,
        'width': width,
        'count': 1,
        'dtype': 'float32',
        'nodata': np.nan,
        'crs': product.getSceneCRS().toString(),  # Convert CRS to string
        'transform': product.getSceneGeoCoding().getImageToMapTransform()  # Get transformation
    }

    # Initialize arrays for line-by-line processing
    sum_amplitude = np.zeros(width, dtype=np.float32)
    sum_squared_amplitude = np.zeros(width, dtype=np.float32)
    amplitude_dispersion = np.zeros(width, dtype=np.float32)

    # Create output file
    with rasterio.open(output_file, 'w', **profile) as dst:
        # Process line by line
        for y in range(height):
            if y % 100 == 0:
                logger.info(f"Processing line {y}/{height}")

            # Reset line sums
            sum_amplitude.fill(0)
            sum_squared_amplitude.fill(0)

            # Process each intensity band for current line
            for band_name in intensity_bands:
                band = product.getBand(band_name)
                line_data = np.zeros(width, dtype=np.float32)
                band.readPixels(0, y, width, 1, line_data)

                # Update running sums
                amplitude = np.sqrt(line_data)  # Convert intensity to amplitude
                sum_amplitude += amplitude
                sum_squared_amplitude += amplitude * amplitude

            # Calculate statistics for current line
            mean_amplitude = sum_amplitude / n_images
            
            # Calculate variance
            variance = (sum_squared_amplitude / n_images) - (mean_amplitude * mean_amplitude)
            variance = np.maximum(variance, 0)  # Ensure non-negative variance
            std_amplitude = np.sqrt(variance)

            # Calculate amplitude dispersion for current line
            valid_pixels = mean_amplitude > 0
            amplitude_dispersion.fill(np.nan)
            amplitude_dispersion[valid_pixels] = std_amplitude[valid_pixels] / mean_amplitude[valid_pixels]

            # Write line to output file
            dst.write(amplitude_dispersion.reshape(1, -1), 1, window=((y, y+1), (0, width)))

    # Calculate final statistics
    logger.info("Calculating final statistics...")
    with rasterio.open(output_file) as src:
        amplitude_dispersion_full = src.read(1)
        valid_da = amplitude_dispersion_full[~np.isnan(amplitude_dispersion_full)]
        ps_candidates = np.sum(valid_da < ps_threshold)
        valid_pixels = np.sum(~np.isnan(amplitude_dispersion_full))

    stats = {
        'min_da': float(np.nanmin(valid_da)),
        'max_da': float(np.nanmax(valid_da)),
        'mean_da': float(np.nanmean(valid_da)),
        'median_da': float(np.nanmedian(valid_da)),
        'ps_candidates': int(ps_candidates),
        'total_valid_pixels': int(valid_pixels),
        'processed_images': n_images
    }

    logger.info("Processing completed successfully")
    logger.info(f"Found {ps_candidates} PS candidates (DA < {ps_threshold})")

    # Close the product
    product.dispose()

    return stats


if __name__ == "__main__":
    # Example usage
    input_dim_file = "/path/to/your/stack.dim"
    output_file = "/path/to/your/amplitude_dispersion.tif"

    try:
        stats = calculate_amplitude_dispersion_snap(input_dim_file, output_file)
        print("Statistics:", stats)
    except Exception as e:
        logging.error(f"Error during processing: {str(e)}")
```

Key changes in this version:

1. Changed input to read a single BEAM-DIMAP file instead of multiple TIFF files
2. Implemented line-by-line processing to manage memory usage
3. Added handling for intensity bands from SNAP (selecting bands that start with 'Intensity')
4. Modified the geotransform and projection handling to work with SNAP's metadata
5. Implemented proper cleanup with product.dispose()
6. Maintained the same statistical output format for consistency
7. Added memory-efficient processing by working with one line at a time
8. Converted intensity values to amplitude by taking the square root

The code maintains the same functionality as the original but processes BEAM-DIMAP files line by line to handle memory constraints. You'll need to ensure that esa_snappy is properly installed and configured in your environment for this to work.