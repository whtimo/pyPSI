Claude 3.5 Sonet on 2024-11-29

> I am developing a permanent scatterer interferometry workflow in Python. After having connected the PS points via triangulation, estimated the height, velocity, and residual differences along the edges and getting the temporal coherence for each edge, I need now to connect each point in the network to a given reference point along the network edges. The ideal path should be weighted, for example based on the temporal coherence. How to implement that in Python3? Can you just show me the code and not run it in the code interpreter.

I'll help you create a Python code snippet that implements a weighted path finding algorithm to connect PS points to a reference point along the network edges. We'll use NetworkX library for graph operations and Dijkstra's algorithm for finding the optimal path based on temporal coherence weights.

Here's the implementation:

```python
import numpy as np
import networkx as nx

def create_ps_network(ps_points, edges, temporal_coherence):
    """
    Create a weighted network from PS points and edges
    
    Parameters:
    -----------
    ps_points : array-like
        Array of PS points coordinates [(x1,y1), (x2,y2), ...]
    edges : array-like
        Array of edge connections [(point1_idx, point2_idx), ...]
    temporal_coherence : array-like
        Temporal coherence values for each edge
        
    Returns:
    --------
    G : networkx.Graph
        Weighted graph representing the PS network
    """
    # Create an empty undirected graph
    G = nx.Graph()
    
    # Add nodes (PS points)
    for i, point in enumerate(ps_points):
        G.add_node(i, pos=point)
    
    # Add edges with weights based on temporal coherence
    # Convert temporal coherence to weights (higher coherence = lower weight)
    weights = 1 - np.array(temporal_coherence)
    
    for (point1, point2), weight in zip(edges, weights):
        G.add_edge(point1, point2, weight=weight)
    
    return G

def find_optimal_paths_to_reference(G, reference_point):
    """
    Find optimal paths from all points to the reference point
    
    Parameters:
    -----------
    G : networkx.Graph
        Weighted graph representing the PS network
    reference_point : int
        Index of the reference point
        
    Returns:
    --------
    paths : dict
        Dictionary containing optimal paths from each point to reference
    distances : dict
        Dictionary containing accumulated weights along optimal paths
    """
    # Calculate shortest paths using Dijkstra's algorithm
    paths = nx.single_source_dijkstra_path(G, reference_point, weight='weight')
    distances = nx.single_source_dijkstra_path_length(G, reference_point, weight='weight')
    
    return paths, distances

def extract_path_parameters(G, paths, heights, velocities):
    """
    Extract height and velocity differences along optimal paths
    
    Parameters:
    -----------
    G : networkx.Graph
        Weighted graph representing the PS network
    paths : dict
        Dictionary containing optimal paths from each point to reference
    heights : array-like
        Height values for each PS point
    velocities : array-like
        Velocity values for each PS point
        
    Returns:
    --------
    path_parameters : dict
        Dictionary containing accumulated height and velocity differences
    """
    path_parameters = {}
    
    for point, path in paths.items():
        if len(path) > 1:  # Skip reference point
            height_diff = 0
            velocity_diff = 0
            
            # Calculate cumulative differences along the path
            for i in range(len(path)-1):
                current = path[i]
                next_point = path[i+1]
                
                height_diff += heights[next_point] - heights[current]
                velocity_diff += velocities[next_point] - velocities[current]
            
            path_parameters[point] = {
                'height_difference': height_diff,
                'velocity_difference': velocity_diff,
                'path': path
            }
    
    return path_parameters

# Example usage:
"""
# Assuming you have these variables:
ps_points = [(x1,y1), (x2,y2), ...]  # PS point coordinates
edges = [(0,1), (1,2), ...]  # Edge connections
temporal_coherence = [0.8, 0.7, ...]  # Temporal coherence for each edge
heights = [100, 102, ...]  # Height values for each point
velocities = [-2.1, -1.9, ...]  # Velocity values for each point
reference_point = 0  # Index of reference point

# Create the network
G = create_ps_network(ps_points, edges, temporal_coherence)

# Find optimal paths
paths, distances = find_optimal_paths_to_reference(G, reference_point)

# Extract parameters along paths
path_parameters = extract_path_parameters(G, paths, heights, velocities)
"""
```

This implementation includes several key components:

1. `create_ps_network`: Creates a NetworkX graph from PS points and edges, with weights based on temporal coherence.
2. `find_optimal_paths_to_reference`: Uses Dijkstra's algorithm to find the optimal (lowest weight) paths from all points to the reference point.
3. `extract_path_parameters`: Calculates cumulative height and velocity differences along the optimal paths.

Key features of this implementation:

- Uses temporal coherence as weights (converted to weights where higher coherence = lower weight)
- Implements weighted path finding using Dijkstra's algorithm
- Tracks both the optimal paths and their accumulated weights
- Calculates cumulative parameter differences (height, velocity) along the paths
- Uses NetworkX for efficient graph operations

To use this code, you would need to provide:
- PS point coordinates
- Edge connections
- Temporal coherence values for each edge
- Height and velocity values for each point
- Reference point index

The weights are calculated as `1 - temporal_coherence` so that higher coherence results in lower weights (preferred paths). You can modify this weighting scheme based on your specific requirements.

> Trying to implement the code you created, there is a difference in the data formats. The code you created requires the following

<<<
edges = [(0,1), (1,2), ...]  # Edge connections
temporal_coherence = [0.8, 0.7, ...]  # Temporal coherence for each edge
heights = [100, 102, ...]  # Height values for each point
velocities = [-2.1, -1.9, ...]  # Velocity values for each point
>>>

but, the 'load_network_parameters' parameters I use, gives the data in a different format. Below is the implementation:

<<<
def load_network_parameters(filename):  # Added from previously generated code
    """
    Load network parameters from HDF5 file

    Parameters:
    -----------
    filename: str
        Path to the HDF5 file

    Returns:
    --------
    params: dict
        Dictionary containing the network parameters
    """
    params = {
        'height_errors': {},
        'velocities': {},
        'temporal_coherences': {},
        'residuals': {},
        'network_edges': {}
    }

    with h5py.File(filename, 'r') as f:
        data_group = f['network_parameters']
        network_group = f['network_edges']

        edge_ids = [id.decode('utf-8') for id in data_group['edge_ids'][:]]
        start_points = [p.decode('utf-8') for p in network_group['start_points'][:]]
        end_points = [p.decode('utf-8') for p in network_group['end_points'][:]]

        for i, edge_id in enumerate(edge_ids):
            # Store parameter data
            params['height_errors'][edge_id] = data_group['height_errors'][i]
            params['velocities'][edge_id] = data_group['velocities'][i]
            params['temporal_coherences'][edge_id] = data_group['temporal_coherences'][i]
            params['residuals'][edge_id] = data_group['residuals'][i]

            # Store network edge information
            params['network_edges'][edge_id] = {
                'start_point': start_points[i],
                'end_point': end_points[i]
            }

    return params
>>>

To make that work, please either change the 'load_network_parameters' function or provide me with a function that brings the data into the right format. Please only show me the code and do not run it in the code interpreter.


I'll provide you with a conversion function that transforms the data from your HDF5 format into the format required by the PS network analysis code. Here's the function:

```python
def convert_network_parameters(params):
    """
    Convert network parameters from HDF5 format to the format required for PS network analysis

    Parameters:
    -----------
    params: dict
        Dictionary containing the network parameters as loaded from HDF5 file
        Contains 'height_errors', 'velocities', 'temporal_coherences', 'residuals', 'network_edges'

    Returns:
    --------
    tuple:
        (edges, temporal_coherence, heights, velocities, ps_points_map)
        - edges: list of tuples [(point1_idx, point2_idx), ...]
        - temporal_coherence: list of coherence values [float, ...]
        - heights: list of height values [float, ...]
        - velocities: list of velocity values [float, ...]
        - ps_points_map: dict mapping PS point IDs to their indices
    """
    # Create a mapping of PS point IDs to indices
    ps_points = set()
    for edge_id in params['network_edges']:
        ps_points.add(params['network_edges'][edge_id]['start_point'])
        ps_points.add(params['network_edges'][edge_id]['end_point'])
    
    ps_points_map = {point_id: idx for idx, point_id in enumerate(sorted(ps_points))}
    
    # Convert edges to index-based format
    edges = []
    temporal_coherence = []
    edge_heights = []
    edge_velocities = []
    
    for edge_id in params['network_edges']:
        start_idx = ps_points_map[params['network_edges'][edge_id]['start_point']]
        end_idx = ps_points_map[params['network_edges'][edge_id]['end_point']]
        
        edges.append((start_idx, end_idx))
        temporal_coherence.append(params['temporal_coherences'][edge_id])
        edge_heights.append(params['height_errors'][edge_id])
        edge_velocities.append(params['velocities'][edge_id])
    
    # Initialize heights and velocities arrays for all points
    num_points = len(ps_points_map)
    heights = [0.0] * num_points
    velocities = [0.0] * num_points
    
    # Accumulate height and velocity differences along edges
    # Note: This is a simple accumulation - you might need to adjust based on your specific needs
    for i, (start_idx, end_idx) in enumerate(edges):
        heights[end_idx] = heights[start_idx] + edge_heights[i]
        velocities[end_idx] = velocities[start_idx] + edge_velocities[i]
    
    return edges, temporal_coherence, heights, velocities, ps_points_map

# Example usage:
"""
# Load the network parameters
params = load_network_parameters('network_params.h5')

# Convert to required format
edges, temporal_coherence, heights, velocities, ps_points_map = convert_network_parameters(params)

# Now you can use these with the PS network analysis code
G = create_ps_network(ps_points, edges, temporal_coherence)
paths, distances = find_optimal_paths_to_reference(G, reference_point)
path_parameters = extract_path_parameters(G, paths, heights, velocities)
"""
```

This conversion function:

1. Creates a mapping between PS point IDs (strings) and numerical indices
2. Converts the edge connections to use these numerical indices
3. Extracts temporal coherence values in the required list format
4. Converts height and velocity differences to absolute values for each point
5. Returns all data in the format required by the PS network analysis code

Key features:
- Maintains a mapping between original PS point IDs and indices
- Handles the conversion of edge-based measurements to point-based values
- Preserves all necessary information for the network analysis
- Returns both the converted data and the mapping to reference original point IDs

Note that the height and velocity calculations in this implementation are simplified. Depending on your specific requirements, you might need to adjust how these values are accumulated or calculated for each point.

The ps_points_map returned by the function allows you to translate between the original PS point IDs and the numerical indices used in the network analysis.


> Thanks, but there is a problem in the 'extract_path_parameters' function. Actually, the function needs to add the velocity, heights, and residuals from the edges up, not the points. So, the frame of the function should be like:

<<<


def extract_path_parameters(G, paths, heights, velocities, residuals):
    """
    Extract height and velocity differences along optimal paths

    Parameters:
    -----------
    G : networkx.Graph
        Weighted graph representing the PS network
    paths : dict
        Dictionary containing optimal paths from each point to reference
    heights : array-like
        Height values for each edge
    velocities : array-like
        Velocity values for each edge
    residuals : array-like
    	Array of residual values for each edge

    Returns:
    --------
    path_parameters : dict
        Dictionary containing accumulated height, velocity, and residual differences
    """
    path_parameters = {}

    for point, path in paths.items():
        if len(path) > 1:  # Skip reference point
            height_diff = 0
            velocity_diff = 0
            residual_diff = ??

            # Calculate cumulative differences along the path
            for i in range(len(path) - 1):
                current = path[i]
                next_point = path[i + 1]

                edge_id = ??

                height_diff += heights[edge_id]
                velocity_diff += velocities[edge_id]
                residual_diff += residuals[edge_id]

            path_parameters[point] = {
                'height_difference': height_diff,
                'velocity_difference': velocity_diff,
                'residual_difference': residual_diff
                'path': path
            }

    return path_parameters

>>>

Please improve the code, especially the parts marked with ?? need to change. Only show me the code, do not run it in the code interpreter.


Here's the improved `extract_path_parameters` function that correctly handles edge-based parameters:

```python
def extract_path_parameters(G, paths, heights, velocities, residuals):
    """
    Extract height and velocity differences along optimal paths

    Parameters:
    -----------
    G : networkx.Graph
        Weighted graph representing the PS network
    paths : dict
        Dictionary containing optimal paths from each point to reference
    heights : dict
        Height values for each edge (edge_id: height_value)
    velocities : dict
        Velocity values for each edge (edge_id: velocity_value)
    residuals : dict
        Residual values for each edge (edge_id: residual_value)

    Returns:
    --------
    path_parameters : dict
        Dictionary containing accumulated height, velocity, and residual differences
    """
    path_parameters = {}

    for point, path in paths.items():
        if len(path) > 1:  # Skip reference point
            height_diff = 0
            velocity_diff = 0
            residual_diff = 0

            # Calculate cumulative differences along the path
            for i in range(len(path) - 1):
                current = path[i]
                next_point = path[i + 1]

                # Get edge ID in both possible directions
                edge_forward = f"{current}_{next_point}"
                edge_backward = f"{next_point}_{current}"

                # Determine if we need to flip the sign based on edge direction
                if edge_forward in heights:
                    edge_id = edge_forward
                    sign = 1
                else:
                    edge_id = edge_backward
                    sign = -1

                height_diff += sign * heights[edge_id]
                velocity_diff += sign * velocities[edge_id]
                residual_diff += abs(residuals[edge_id])  # Residuals are always positive

            path_parameters[point] = {
                'height_difference': height_diff,
                'velocity_difference': velocity_diff,
                'residual_difference': residual_diff,
                'path': path
            }

    return path_parameters
```

Key improvements in this version:
1. Handles edge-based parameters instead of point-based parameters
2. Properly manages edge directions and sign conventions
3. Creates edge IDs using point pairs
4. Handles bidirectional edges (can find the edge regardless of point order)
5. Properly accumulates residuals (using absolute values)
6. Uses dictionary-based edge parameter lookup instead of array indexing

The function assumes that edge IDs are formatted as "point1_point2" strings, but you can modify the edge ID format according to your specific needs.

> No, didn't work. In the networkx.Graph, how to get the edge_id from the two point ids?


Ah, I understand now. In a NetworkX Graph, we can get the edge data using the `get_edge_data()` method. Here's the corrected `extract_path_parameters` function:

```python
def extract_path_parameters(G, paths, heights, velocities, residuals):
    """
    Extract height and velocity differences along optimal paths

    Parameters:
    -----------
    G : networkx.Graph
        Weighted graph representing the PS network
    paths : dict
        Dictionary containing optimal paths from each point to reference
    heights : dict
        Height values for each edge (edge_id: height_value)
    velocities : dict
        Velocity values for each edge (edge_id: velocity_value)
    residuals : dict
        Residual values for each edge (edge_id: residual_value)

    Returns:
    --------
    path_parameters : dict
        Dictionary containing accumulated height, velocity, and residual differences
    """
    path_parameters = {}

    for point, path in paths.items():
        if len(path) > 1:  # Skip reference point
            height_diff = 0
            velocity_diff = 0
            residual_diff = 0

            # Calculate cumulative differences along the path
            for i in range(len(path) - 1):
                current = path[i]
                next_point = path[i + 1]

                # Get edge data from the graph
                edge_data = G.get_edge_data(current, next_point)
                edge_id = edge_data['edge_id']  # Assuming edge_id is stored in edge attributes

                height_diff += heights[edge_id]
                velocity_diff += velocities[edge_id]
                residual_diff += residuals[edge_id]

            path_parameters[point] = {
                'height_difference': height_diff,
                'velocity_difference': velocity_diff,
                'residual_difference': residual_diff,
                'path': path
            }

    return path_parameters
```

This means we also need to modify the `create_ps_network` function to store the edge_id in the edge attributes when creating the graph:

```python
def create_ps_network(ps_points, edges, temporal_coherence, edge_ids):
    """
    Create a weighted network from PS points and edges
    
    Parameters:
    -----------
    ps_points : array-like
        Array of PS points coordinates [(x1,y1), (x2,y2), ...]
    edges : array-like
        Array of edge connections [(point1_idx, point2_idx), ...]
    temporal_coherence : array-like
        Temporal coherence values for each edge
    edge_ids : array-like
        IDs for each edge
        
    Returns:
    --------
    G : networkx.Graph
        Weighted graph representing the PS network
    """
    # Create an empty undirected graph
    G = nx.Graph()
    
    # Add nodes (PS points)
    for i, point in enumerate(ps_points):
        G.add_node(i, pos=point)
    
    # Add edges with weights based on temporal coherence
    # Convert temporal coherence to weights (higher coherence = lower weight)
    weights = 1 - np.array(temporal_coherence)
    
    for (point1, point2), weight, edge_id in zip(edges, weights, edge_ids):
        G.add_edge(point1, point2, weight=weight, edge_id=edge_id)
    
    return G
```

Now the edge_id is stored in the graph structure and can be retrieved when calculating the path parameters. This assumes that the edge_ids match the keys in your heights, velocities, and residuals dictionaries.

> Good. Now, I want to save the final results in a suitable file format. The results are given in path_parameters.

<<<
path_parameters[point] = {
                'height_difference': height_diff,
                'velocity_difference': velocity_diff,
                'residual_difference': residual_diff,
                'path': path
            }
>>>

For each point, from a given pandas data frame with df[['point_id", 'sample', 'line']].values should save the point id, sample, line, height_difference, velocity_difference, and the array of residual_difference. The reference point given with an id is saved as well with height_difference, elocity_difference, and the array of residual_difference all set to zero. The reference point will not be included in the path_parameters. 

Please only show me the code and do not run it in the code interpreter.

Here's a function to save the results in HDF5 format, combining the path parameters with the point coordinates and including the reference point:

```python
def save_path_parameters(path_parameters, df, reference_point_id, filename='path_parameters.h5'):
    """
    Save path parameters and point coordinates to HDF5 file

    Parameters:
    -----------
    path_parameters: dict
        Dictionary containing path parameters for each point
    df: pandas.DataFrame
        DataFrame containing point coordinates with columns ['point_id', 'sample', 'line']
    reference_point_id: str
        ID of the reference point
    filename: str
        Path to save the HDF5 file
    """
    import h5py
    import numpy as np

    # Create coordinate lookup dictionary
    coord_lookup = {row['point_id']: (row['sample'], row['line']) 
                   for _, row in df[['point_id', 'sample', 'line']].iterrows()}

    # Prepare data arrays
    point_ids = list(path_parameters.keys()) + [reference_point_id]
    n_points = len(point_ids)

    # Initialize arrays
    samples = np.zeros(n_points, dtype=np.float32)
    lines = np.zeros(n_points, dtype=np.float32)
    heights = np.zeros(n_points, dtype=np.float32)
    velocities = np.zeros(n_points, dtype=np.float32)
    residuals = np.zeros(n_points, dtype=np.float32)

    # Fill arrays with path parameters data
    for i, point_id in enumerate(point_ids[:-1]):  # Exclude reference point
        samples[i], lines[i] = coord_lookup[point_id]
        heights[i] = path_parameters[point_id]['height_difference']
        velocities[i] = path_parameters[point_id]['velocity_difference']
        residuals[i] = path_parameters[point_id]['residual_difference']

    # Add reference point (last index)
    ref_idx = n_points - 1
    samples[ref_idx], lines[ref_idx] = coord_lookup[reference_point_id]
    # Reference point parameters are already zero from initialization

    # Save to HDF5 file
    with h5py.File(filename, 'w') as f:
        # Create main group
        results = f.create_group('path_parameters')

        # Store point IDs as ASCII strings
        dt = h5py.special_dtype(vlen=str)
        point_ids_dataset = results.create_dataset('point_ids', (n_points,), dtype=dt)
        point_ids_dataset[:] = point_ids

        # Store coordinates and parameters
        results.create_dataset('sample', data=samples)
        results.create_dataset('line', data=lines)
        results.create_dataset('height_difference', data=heights)
        results.create_dataset('velocity_difference', data=velocities)
        results.create_dataset('residual_difference', data=residuals)

        # Store reference point ID as attribute
        results.attrs['reference_point_id'] = reference_point_id

        # Store metadata
        results.attrs['creation_date'] = str(datetime.datetime.now())
        results.attrs['number_of_points'] = n_points

def load_path_parameters(filename='path_parameters.h5'):
    """
    Load path parameters from HDF5 file

    Parameters:
    -----------
    filename: str
        Path to the HDF5 file

    Returns:
    --------
    dict:
        Dictionary containing all path parameters and point information
    """
    import h5py
    
    results = {}
    
    with h5py.File(filename, 'r') as f:
        params = f['path_parameters']
        
        # Get all point IDs
        point_ids = [pid.decode('utf-8') if isinstance(pid, bytes) 
                    else pid for pid in params['point_ids'][:]]
        
        # Get reference point ID
        results['reference_point_id'] = params.attrs['reference_point_id']
        
        # Create points dictionary
        results['points'] = {}
        for i, point_id in enumerate(point_ids):
            results['points'][point_id] = {
                'sample': params['sample'][i],
                'line': params['line'][i],
                'height_difference': params['height_difference'][i],
                'velocity_difference': params['velocity_difference'][i],
                'residual_difference': params['residual_difference'][i]
            }
        
        # Store metadata
        results['metadata'] = {
            'creation_date': params.attrs['creation_date'],
            'number_of_points': params.attrs['number_of_points']
        }
    
    return results
```

This implementation:

1. Saves the data in HDF5 format, which is efficient for large datasets
2. Includes both save and load functions for completeness
3. Stores:
   - Point IDs as strings
   - Sample and line coordinates
   - Height, velocity, and residual differences
   - Reference point ID and its zero values
   - Metadata including creation date and number of points
4. Handles the reference point separately, setting all its differences to zero
5. Preserves the coordinate information from the original DataFrame
6. Uses efficient numpy arrays for numerical data
7. Includes proper type handling for string data (point IDs)

The HDF5 structure is:
```
path_parameters/
    ├── point_ids (dataset)
    ├── sample (dataset)
    ├── line (dataset)
    ├── height_difference (dataset)
    ├── velocity_difference (dataset)
    ├── residual_difference (dataset)
    └── attributes
        ├── reference_point_id
        ├── creation_date
        └── number_of_points
```

> Good. Using the results loaded with 'load_path_parameters' shown below, display the velocities at sample and line positions with matplotlib. The background should be a SAR image loaded from a complex tiff file.

<<<
def load_path_parameters(filename='path_parameters.h5'):
    """
    Load path parameters from HDF5 file

    Parameters:
    -----------
    filename: str
        Path to the HDF5 file

    Returns:
    --------
    dict:
        Dictionary containing all path parameters and point information
    """
    import h5py
    
    results = {}
    
    with h5py.File(filename, 'r') as f:
        params = f['path_parameters']
        
        # Get all point IDs
        point_ids = [pid.decode('utf-8') if isinstance(pid, bytes) 
                    else pid for pid in params['point_ids'][:]]
        
        # Get reference point ID
        results['reference_point_id'] = params.attrs['reference_point_id']
        
        # Create points dictionary
        results['points'] = {}
        for i, point_id in enumerate(point_ids):
            results['points'][point_id] = {
                'sample': params['sample'][i],
                'line': params['line'][i],
                'height_difference': params['height_difference'][i],
                'velocity_difference': params['velocity_difference'][i],
                'residual_difference': params['residual_difference'][i]
            }
        
        # Store metadata
        results['metadata'] = {
            'creation_date': params.attrs['creation_date'],
            'number_of_points': params.attrs['number_of_points']
        }
    
    return results
>>

Please only show me the code and do not run it in the code interpreter.

Here's a function to plot the velocities over a SAR background image:

```python
def plot_velocities_on_sar(results, sar_image_path, 
                          output_path=None, 
                          cmap='RdYlBu_r', 
                          marker_size=20, 
                          dpi=300):
    """
    Plot velocity differences over SAR background image

    Parameters:
    -----------
    results: dict
        Results dictionary from load_path_parameters
    sar_image_path: str
        Path to the complex SAR TIFF image
    output_path: str, optional
        Path to save the figure. If None, display only
    cmap: str, optional
        Colormap for velocity values
    marker_size: int, optional
        Size of the scatter plot markers
    dpi: int, optional
        DPI for saved figure
    """
    import matplotlib.pyplot as plt
    import numpy as np
    import rasterio
    from matplotlib.colors import Normalize

    # Read SAR image
    with rasterio.open(sar_image_path) as src:
        sar_image = src.read(1)  # Read first band
        transform = src.transform

    # Extract coordinates and velocities
    samples = []
    lines = []
    velocities = []
    
    for point_id, point_data in results['points'].items():
        samples.append(point_data['sample'])
        lines.append(point_data['line'])
        velocities.append(point_data['velocity_difference'])

    samples = np.array(samples)
    lines = np.array(lines)
    velocities = np.array(velocities)

    # Create figure
    plt.figure(figsize=(12, 8))

    # Plot SAR background
    # Convert complex SAR image to intensity in dB
    sar_db = 10 * np.log10(np.abs(sar_image)**2)
    
    # Normalize SAR image for display
    sar_norm = Normalize(vmin=np.percentile(sar_db, 5), 
                        vmax=np.percentile(sar_db, 95))
    
    plt.imshow(sar_db, 
               cmap='gray', 
               norm=sar_norm, 
               extent=[0, sar_image.shape[1], sar_image.shape[0], 0])

    # Plot velocities
    scatter = plt.scatter(samples, 
                         lines, 
                         c=velocities, 
                         cmap=cmap,
                         s=marker_size, 
                         alpha=0.7)

    # Highlight reference point
    ref_point = results['points'][results['reference_point_id']]
    plt.scatter(ref_point['sample'], 
               ref_point['line'], 
               c='yellow', 
               marker='*', 
               s=marker_size*2, 
               label='Reference Point')

    # Add colorbar
    cbar = plt.colorbar(scatter)
    cbar.set_label('Velocity Difference [mm/year]', rotation=270, labelpad=15)

    # Set labels and title
    plt.xlabel('Sample')
    plt.ylabel('Line')
    plt.title('PS Velocity Differences')
    plt.legend()

    # Add grid
    plt.grid(True, alpha=0.3)

    # Tight layout
    plt.tight_layout()

    # Save or show
    if output_path:
        plt.savefig(output_path, dpi=dpi, bbox_inches='tight')
        plt.close()
    else:
        plt.show()

# Example usage:
"""
# Load results
results = load_path_parameters('path_parameters.h5')

# Plot
plot_velocities_on_sar(
    results,
    sar_image_path='sar_image.tiff',
    output_path='velocity_map.png',
    cmap='RdYlBu_r',  # Red-Yellow-Blue colormap, reversed
    marker_size=20,
    dpi=300
)
"""
```

This implementation:

1. Uses rasterio to read the complex SAR TIFF file
2. Converts the complex SAR data to intensity in dB for better visualization
3. Plots the SAR image in grayscale with normalized intensity values
4. Overlays PS points colored by their velocity differences
5. Highlights the reference point with a yellow star
6. Includes:
   - Colorbar with proper units
   - Grid
   - Labels and title
   - Legend
7. Provides options for:
   - Custom colormap
   - Marker size
   - Output resolution (DPI)
   - Save to file or display
8. Uses proper normalization for both SAR background and velocity values
9. Handles the plotting layout professionally

The function creates a professional-looking visualization that combines:
- SAR background in grayscale
- Colored PS points showing velocity differences
- Clear reference point identification
- Proper scientific annotation and labeling

> Great. Now, please create the same visualization, but reading the point data from a CSV file with the following format:

<<<

Reference Point: id=345711 || lat=36.12920995 || lon=-115.15253515 
ID,LAT,LON,HEIGHT,Velocity [mm/year]
1,36.142802,-115.0967,562.98956,-0.39950143
...
>>>

The first line of the CSV file has to be skipped. Please only show me the code and do not run it in the code interpreter

Here's a function to read the CSV data and create the same visualization:

```python
def load_points_from_csv(csv_path):
    """
    Load point data from CSV file with reference point in header

    Parameters:
    -----------
    csv_path: str
        Path to the CSV file

    Returns:
    --------
    dict:
        Dictionary containing points data and reference point information
    """
    import pandas as pd
    import re

    # Read reference point from first line
    with open(csv_path, 'r') as f:
        ref_line = f.readline()
        
    # Extract reference point information using regex
    ref_match = re.match(r'Reference Point: id=(\d+) \|\| lat=([\d.-]+) \|\| lon=([\d.-]+)', ref_line)
    ref_id = ref_match.group(1)
    ref_lat = float(ref_match.group(2))
    ref_lon = float(ref_match.group(3))

    # Read the actual data
    df = pd.read_csv(csv_path, skiprows=1)

    # Create results dictionary similar to HDF5 format
    results = {
        'reference_point_id': ref_id,
        'points': {},
        'metadata': {
            'creation_date': str(datetime.datetime.now()),
            'number_of_points': len(df) + 1  # Including reference point
        }
    }

    # Add points from DataFrame
    for _, row in df.iterrows():
        results['points'][str(row['ID'])] = {
            'lat': row['LAT'],
            'lon': row['LON'],
            'height_difference': row['HEIGHT'],
            'velocity_difference': row['Velocity [mm/year]']
        }

    # Add reference point with zero differences
    results['points'][ref_id] = {
        'lat': ref_lat,
        'lon': ref_lon,
        'height_difference': 0.0,
        'velocity_difference': 0.0
    }

    return results

def plot_velocities_on_sar_geo(results, sar_image_path, 
                              output_path=None, 
                              cmap='RdYlBu_r', 
                              marker_size=20, 
                              dpi=300):
    """
    Plot velocity differences over SAR background image using geographic coordinates

    Parameters:
    -----------
    results: dict
        Results dictionary from load_points_from_csv
    sar_image_path: str
        Path to the geocoded SAR TIFF image
    output_path: str, optional
        Path to save the figure
    cmap: str, optional
        Colormap for velocity values
    marker_size: int, optional
        Size of the scatter plot markers
    dpi: int, optional
        DPI for saved figure
    """
    import matplotlib.pyplot as plt
    import numpy as np
    import rasterio
    from matplotlib.colors import Normalize

    # Read SAR image
    with rasterio.open(sar_image_path) as src:
        sar_image = src.read(1)
        transform = src.transform
        crs = src.crs

    # Extract coordinates and velocities
    lats = []
    lons = []
    velocities = []
    
    for point_id, point_data in results['points'].items():
        lats.append(point_data['lat'])
        lons.append(point_data['lon'])
        velocities.append(point_data['velocity_difference'])

    lats = np.array(lats)
    lons = np.array(lons)
    velocities = np.array(velocities)

    # Create figure
    plt.figure(figsize=(12, 8))

    # Plot SAR background
    sar_db = 10 * np.log10(np.abs(sar_image)**2)
    sar_norm = Normalize(vmin=np.percentile(sar_db, 5), 
                        vmax=np.percentile(sar_db, 95))
    
    # Plot using geographic extent
    extent = [
        transform.xoff,
        transform.xoff + transform.a * sar_image.shape[1],
        transform.yoff + transform.e * sar_image.shape[0],
        transform.yoff
    ]
    
    plt.imshow(sar_db, 
               cmap='gray', 
               norm=sar_norm, 
               extent=extent)

    # Plot velocities
    scatter = plt.scatter(lons, 
                         lats, 
                         c=velocities, 
                         cmap=cmap,
                         s=marker_size, 
                         alpha=0.7)

    # Highlight reference point
    ref_point = results['points'][results['reference_point_id']]
    plt.scatter(ref_point['lon'], 
               ref_point['lat'], 
               c='yellow', 
               marker='*', 
               s=marker_size*2, 
               label='Reference Point')

    # Add colorbar
    cbar = plt.colorbar(scatter)
    cbar.set_label('Velocity [mm/year]', rotation=270, labelpad=15)

    # Set labels and title
    plt.xlabel('Longitude')
    plt.ylabel('Latitude')
    plt.title('PS Velocity Map')
    plt.legend()

    # Add grid
    plt.grid(True, alpha=0.3)

    # Tight layout
    plt.tight_layout()

    # Save or show
    if output_path:
        plt.savefig(output_path, dpi=dpi, bbox_inches='tight')
        plt.close()
    else:
        plt.show()

# Example usage:
"""
# Load points from CSV
results = load_points_from_csv('points.csv')

# Create visualization
plot_velocities_on_sar_geo(
    results,
    sar_image_path='sar_image.tiff',
    output_path='velocity_map.png',
    cmap='RdYlBu_r',
    marker_size=20,
    dpi=300
)
"""
```

Key changes from the previous version:
1. New `load_points_from_csv` function to handle the specific CSV format
2. Modified plotting function to work with geographic coordinates
3. Proper handling of the reference point information from CSV header
4. Updated axis labels to show Latitude/Longitude instead of Sample/Line
5. Uses rasterio's transform to properly georeference the SAR image
6. Maintains the same visualization style but with geographic coordinates

The code assumes:
- The SAR image is properly geocoded (in the same coordinate system as the points)
- The CSV file follows the exact format specified
- The SAR image has proper georeference information in its metadata

The visualization will now show the points in their correct geographic positions over the SAR background image.

> Oh no, I made a mistake. I don't want it displayed in LAT, LON coordinates, but in SAMPLE and LINE pixel coordinates. They are in two different CSV files. So, I think we need  to combine these files first and then visualize. I show you the three files:

<<<
Reference Point: id=394838 || lat=36.12920995 || lon=-115.15253515 
ID,LAT,LON,HEIGHT,Samples [pix]
1,36.142802,-115.0967,562.98956,194
...
>>>

<<<
Reference Point: id=394838 || lat=36.12920995 || lon=-115.15253515 
ID,LAT,LON,HEIGHT,Lines [pix]
1,36.142802,-115.0967,562.98956,2
...
>>>

<<<
Reference Point: id=394838 || lat=36.12920995 || lon=-115.15253515 
ID,LAT,LON,HEIGHT,Samples [pix]
1,36.142802,-115.0967,562.98956,194
...
>>>

The first line of each CSV file has to be skipped. Please only show me the code and do not run it in the code interpreter.

Here's the modified code to handle the three CSV files and create the visualization in pixel coordinates:

```python
def load_and_combine_csv_data(velocity_csv, samples_csv, lines_csv):
    """
    Load and combine data from three CSV files containing velocities, samples, and lines

    Parameters:
    -----------
    velocity_csv: str
        Path to CSV file containing velocity data
    samples_csv: str
        Path to CSV file containing sample coordinates
    lines_csv: str
        Path to CSV file containing line coordinates

    Returns:
    --------
    dict:
        Dictionary containing combined point data and reference point information
    """
    import pandas as pd
    import re

    # Read reference point from first line (using velocity file)
    with open(velocity_csv, 'r') as f:
        ref_line = f.readline()
        
    # Extract reference point information using regex
    ref_match = re.match(r'Reference Point: id=(\d+) \|\| lat=([\d.-]+) \|\| lon=([\d.-]+)', ref_line)
    ref_id = ref_match.group(1)
    ref_lat = float(ref_match.group(2))
    ref_lon = float(ref_match.group(3))

    # Read the data from all files
    df_vel = pd.read_csv(velocity_csv, skiprows=1)
    df_samples = pd.read_csv(samples_csv, skiprows=1)
    df_lines = pd.read_csv(lines_csv, skiprows=1)

    # Merge dataframes on ID
    df_combined = df_vel.merge(df_samples[['ID', 'Samples [pix]']], on='ID', how='inner')
    df_combined = df_combined.merge(df_lines[['ID', 'Lines [pix]']], on='ID', how='inner')

    # Create results dictionary
    results = {
        'reference_point_id': ref_id,
        'points': {},
        'metadata': {
            'creation_date': str(datetime.datetime.now()),
            'number_of_points': len(df_combined) + 1  # Including reference point
        }
    }

    # Add points from combined DataFrame
    for _, row in df_combined.iterrows():
        results['points'][str(row['ID'])] = {
            'sample': row['Samples [pix]'],
            'line': row['Lines [pix]'],
            'lat': row['LAT'],
            'lon': row['LON'],
            'height_difference': row['HEIGHT'],
            'velocity_difference': row['Velocity [mm/year]']
        }

    # Find reference point coordinates in the datasets
    ref_data_sample = df_samples[df_samples['ID'] == int(ref_id)]['Samples [pix]'].iloc[0]
    ref_data_line = df_lines[df_lines['ID'] == int(ref_id)]['Lines [pix]'].iloc[0]

    # Add reference point with zero differences
    results['points'][ref_id] = {
        'sample': ref_data_sample,
        'line': ref_data_line,
        'lat': ref_lat,
        'lon': ref_lon,
        'height_difference': 0.0,
        'velocity_difference': 0.0
    }

    return results

def plot_velocities_on_sar(results, sar_image_path, 
                          output_path=None, 
                          cmap='RdYlBu_r', 
                          marker_size=20, 
                          dpi=300):
    """
    Plot velocity differences over SAR background image using pixel coordinates

    Parameters:
    -----------
    results: dict
        Results dictionary from load_and_combine_csv_data
    sar_image_path: str
        Path to the SAR TIFF image
    output_path: str, optional
        Path to save the figure
    cmap: str, optional
        Colormap for velocity values
    marker_size: int, optional
        Size of the scatter plot markers
    dpi: int, optional
        DPI for saved figure
    """
    import matplotlib.pyplot as plt
    import numpy as np
    import rasterio
    from matplotlib.colors import Normalize

    # Read SAR image
    with rasterio.open(sar_image_path) as src:
        sar_image = src.read(1)

    # Extract coordinates and velocities
    samples = []
    lines = []
    velocities = []
    
    for point_id, point_data in results['points'].items():
        samples.append(point_data['sample'])
        lines.append(point_data['line'])
        velocities.append(point_data['velocity_difference'])

    samples = np.array(samples)
    lines = np.array(lines)
    velocities = np.array(velocities)

    # Create figure
    plt.figure(figsize=(12, 8))

    # Plot SAR background
    sar_db = 10 * np.log10(np.abs(sar_image)**2)
    sar_norm = Normalize(vmin=np.percentile(sar_db, 5), 
                        vmax=np.percentile(sar_db, 95))
    
    plt.imshow(sar_db, 
               cmap='gray', 
               norm=sar_norm,
               extent=[0, sar_image.shape[1], sar_image.shape[0], 0])

    # Plot velocities
    scatter = plt.scatter(samples, 
                         lines, 
                         c=velocities, 
                         cmap=cmap,
                         s=marker_size, 
                         alpha=0.7)

    # Highlight reference point
    ref_point = results['points'][results['reference_point_id']]
    plt.scatter(ref_point['sample'], 
               ref_point['line'], 
               c='yellow', 
               marker='*', 
               s=marker_size*2, 
               label='Reference Point')

    # Add colorbar
    cbar = plt.colorbar(scatter)
    cbar.set_label('Velocity [mm/year]', rotation=270, labelpad=15)

    # Set labels and title
    plt.xlabel('Sample [pix]')
    plt.ylabel('Line [pix]')
    plt.title('PS Velocity Map')
    plt.legend()

    # Add grid
    plt.grid(True, alpha=0.3)

    # Tight layout
    plt.tight_layout()

    # Save or show
    if output_path:
        plt.savefig(output_path, dpi=dpi, bbox_inches='tight')
        plt.close()
    else:
        plt.show()

# Example usage:
"""
# Load and combine data
results = load_and_combine_csv_data(
    velocity_csv='velocity.csv',
    samples_csv='samples.csv',
    lines_csv='lines.csv'
)

# Create visualization
plot_velocities_on_sar(
    results,
    sar_image_path='sar_image.tiff',
    output_path='velocity_map.png',
    cmap='RdYlBu_r',
    marker_size=20,
    dpi=300
)
"""
```

Key changes:
1. New `load_and_combine_csv_data` function to:
   - Read and combine three CSV files
   - Match points across files using ID
   - Handle reference point information
   - Store both pixel coordinates and geographic coordinates
2. Modified plotting function to:
   - Use pixel coordinates (sample/line) instead of geographic coordinates
   - Properly label axes with pixel units
   - Maintain the same visualization style
3. Proper handling of the reference point across all files
4. Merged data validation through pandas

The code assumes:
- All three CSV files have the same reference point information
- All files contain the same points (matched by ID)
- The SAR image is in the correct orientation for the pixel coordinates
- The pixel coordinates are 0-based and match the SAR image dimensions