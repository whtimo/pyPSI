Claude on 2024-12-30

> > I am developing Python3 code for permanent scatterer interferometry. The code I have is estimating the velocity and residual height parameters as expected, but is rather slow. I think it could become faster with parallelization. Where do you think I should parellize the code? <<<class PSIParameterEstimator:
    def __init__(self,
                 wavelength: float,
                 temporal_baselines: np.ndarray,
                 perpendicular_baselines: np.ndarray,
                 range_distances: np.ndarray,
                 incidence_angles: np.ndarray):
        """
        Initialize PSI parameter estimator

        Parameters:
        -----------
        wavelength: float
            Radar wavelength in meters
        temporal_baselines: np.ndarray
            Time differences between master and slave images in days
        perpendicular_baselines: np.ndarray
            Perpendicular baselines in meters
        range_distances: np.ndarray
            Slant range distances in meters
        incidence_angles: np.ndarray
            Local incidence angles in radians
        """
        self.wavelength = wavelength
        self.temporal_baselines_years = temporal_baselines / 365.0 #Timo: temporal baselines need to be given in years
        self.perpendicular_baselines = perpendicular_baselines
        self.range_distances = range_distances
        self.incidence_angles = incidence_angles

    def estimate_parameters(self, phase_differences):
        """
        Estimates height error and velocity along network edges using periodogram approach.

        Args:
            phase_differences (ndarray): Complex phase differences between two PS points

        Returns:
            tuple: (height_error, velocity, temporal_coherence, residuals)
        """
        # Define search spaces for height error and velocity
        height_search = np.linspace(-100, 100, 200)  # meters, adjust range as needed
        velocity_search = np.linspace(-100, 100, 200)  # mm/year, adjust range as needed

        # Initialize coherence matrix
        coherence_matrix = np.zeros((len(height_search), len(velocity_search)))

        # Calculate constants for phase conversion
        height_to_phase = (4 * np.pi / self.wavelength) * (
                self.perpendicular_baselines / (self.range_distances * np.sin(self.incidence_angles))
        )
        velocity_to_phase = (4 * np.pi / self.wavelength) * self.temporal_baselines_years

        # Compute periodogram
        for i, h in enumerate(height_search):
            for j, v in enumerate(velocity_search):
                # Calculate model phases
                #phase_topo = h * height_to_phase
                #phase_motion = v * velocity_to_phase
                #model_phase = phase_topo + phase_motion
                phase_topo = np.angle(np.exp(1j * h * height_to_phase))
                phase_motion = np.angle(np.exp(1j * (v / 1000.0) * velocity_to_phase)) #Timo: velocity is given in mm
                model_phase = np.angle(np.exp(1j * (phase_topo + phase_motion)))

                # Calculate temporal coherence (equation 6.10)
                # temporal_coherence = np.abs(
                #     np.mean(
                #         np.exp(1j * np.angle(phase_differences)) *
                #         np.exp(-1j * model_phase)
                #     )
                # )

                #Timo: The np.angle of the phase difference seems to be a mistake as these are already given in radians
                temporal_coherence = np.abs(
                    np.mean(
                        np.exp(1j * phase_differences) *
                        np.exp(-1j * model_phase)
                    )
                )
                coherence_matrix[i, j] = temporal_coherence

        # Find maximum coherence
        max_idx = np.unravel_index(np.argmax(coherence_matrix), coherence_matrix.shape)
        best_height = height_search[max_idx[0]]
        best_velocity = velocity_search[max_idx[1]]
        max_coherence = coherence_matrix[max_idx]

        # Calculate residuals
        best_phase_topo = np.angle(np.exp(1j * best_height * height_to_phase))
        best_phase_motion = np.angle(np.exp(1j * (best_velocity / 1000) * velocity_to_phase))
        best_model_phase = np.angle(np.exp(1j * (best_phase_topo + best_phase_motion)))
        temporal_coherence2 = np.abs(
            np.mean(
                np.exp(1j * phase_differences) *
                np.exp(-1j * best_model_phase)
            )
        )
        # residuals = np.angle(
        #     np.exp(1j * np.angle(phase_differences)) *
        #     np.exp(-1j * model_phase)
        # )
        # Timo: The np.angle of the phase difference seems to be a mistake as these are already given in radians
        residuals = np.angle(
            np.exp(1j * phase_differences) *
            np.exp(-1j * best_model_phase)
        )

        return best_height, best_velocity, max_coherence


class ParameterEstimator:
    def __init__(self, ps_network):
        """
        Estimate parameters for entire PS network

        Parameters:
        -----------
        ps_network: dict
            Network information including edges and phase data
        """
        self.ps_info = ps_info
        self.points = ps_info['points']
        self.parameter_estimator = PSIParameterEstimator(
            wavelength=ps_network['wavelength'],
            temporal_baselines=ps_network['temporal_baselines'],
            perpendicular_baselines=ps_network['perpendicular_baselines'],
            range_distances=ps_network['range_distances'],
            incidence_angles=ps_network['incidence_angles']
        )

    def estimate_parameters(self, ref_point : int) -> dict:
        """
        Estimate parameters for all edges in the network

        Returns:
        --------
        network_parameters: dict
            Dictionary containing estimated parameters for each edge
        """
        parameters = {
            'height_errors': {},
            'velocities': {},
            'temporal_coherences': {}
        }

        ref_phases = self.points.iloc[ref_point][3:].to_numpy()
        for point_id in range(len(self.points)):
            if point_id != ref_point:
                phases = self.points.iloc[point_id][3:].to_numpy()
                phase_differences = np.angle(np.exp(1j * (ref_phases - phases)))
                height_error, velocity, temporal_coherence = (
                    self.parameter_estimator.estimate_parameters(
                        phase_differences
                    )
                )
                print(f'{point_id} / {len(self.points)} - {height_error},{velocity},{temporal_coherence}')

                parameters['height_errors'][point_id] = height_error
                parameters['velocities'][point_id] = velocity
                parameters['temporal_coherences'][point_id] = temporal_coherence
            else:
                parameters['height_errors'][point_id] = 0.0
                parameters['velocities'][point_id] = 0.0
                parameters['temporal_coherences'][point_id] = 1.0

        return parameters
>>>

Looking at your PSI (Permanent Scatterer Interferometry) code, there are several opportunities for parallelization to improve performance. Here are the main areas where parallelization would be most beneficial:

1. **Main Parameter Estimation Loop**: The most obvious place is in the `ParameterEstimator.estimate_parameters()` method, where you process each point independently relative to the reference point. This is embarrassingly parallel.

2. **Periodogram Computation**: Within `PSIParameterEstimator.estimate_parameters()`, the nested loops for computing the coherence matrix can be parallelized.

Here's how I would modify your code to implement parallelization using Python's `multiprocessing` module:

```python
import multiprocessing as mp
from functools import partial
import numpy as np

class PSIParameterEstimator:
    # ... [previous __init__ code remains the same] ...

    def estimate_parameters(self, phase_differences):
        """
        Parallelized version of parameter estimation
        """
        # Define search spaces for height error and velocity
        height_search = np.linspace(-100, 100, 200)
        velocity_search = np.linspace(-100, 100, 200)

        # Calculate constants for phase conversion
        height_to_phase = (4 * np.pi / self.wavelength) * (
                self.perpendicular_baselines / (self.range_distances * np.sin(self.incidence_angles))
        )
        velocity_to_phase = (4 * np.pi / self.wavelength) * self.temporal_baselines_years

        # Prepare the coherence calculation function for parallel processing
        def calculate_coherence_row(h, velocity_search, phase_differences, height_to_phase, velocity_to_phase):
            coherence_row = np.zeros(len(velocity_search))
            for j, v in enumerate(velocity_search):
                phase_topo = np.angle(np.exp(1j * h * height_to_phase))
                phase_motion = np.angle(np.exp(1j * (v / 1000.0) * velocity_to_phase))
                model_phase = np.angle(np.exp(1j * (phase_topo + phase_motion)))
                
                temporal_coherence = np.abs(
                    np.mean(
                        np.exp(1j * phase_differences) *
                        np.exp(-1j * model_phase)
                    )
                )
                coherence_row[j] = temporal_coherence
            return coherence_row

        # Parallel processing of coherence matrix
        with mp.Pool() as pool:
            func = partial(
                calculate_coherence_row,
                velocity_search=velocity_search,
                phase_differences=phase_differences,
                height_to_phase=height_to_phase,
                velocity_to_phase=velocity_to_phase
            )
            coherence_matrix = np.array(pool.map(func, height_search))

        # Find maximum coherence and calculate results
        max_idx = np.unravel_index(np.argmax(coherence_matrix), coherence_matrix.shape)
        best_height = height_search[max_idx[0]]
        best_velocity = velocity_search[max_idx[1]]
        max_coherence = coherence_matrix[max_idx]

        # Calculate residuals
        best_phase_topo = np.angle(np.exp(1j * best_height * height_to_phase))
        best_phase_motion = np.angle(np.exp(1j * (best_velocity / 1000) * velocity_to_phase))
        best_model_phase = np.angle(np.exp(1j * (best_phase_topo + best_phase_motion)))
        residuals = np.angle(
            np.exp(1j * phase_differences) *
            np.exp(-1j * best_model_phase)
        )

        return best_height, best_velocity, max_coherence

class ParameterEstimator:
    # ... [previous __init__ code remains the same] ...

    def _process_point(self, point_data):
        """
        Process a single point for parallel execution
        """
        point_id, ref_phases = point_data
        if point_id != self.ref_point:
            phases = self.points.iloc[point_id][3:].to_numpy()
            phase_differences = np.angle(np.exp(1j * (ref_phases - phases)))
            height_error, velocity, temporal_coherence = (
                self.parameter_estimator.estimate_parameters(phase_differences)
            )
            return point_id, height_error, velocity, temporal_coherence
        return point_id, 0.0, 0.0, 1.0

    def estimate_parameters(self, ref_point: int) -> dict:
        """
        Parallel version of parameter estimation for all edges
        """
        self.ref_point = ref_point
        parameters = {
            'height_errors': {},
            'velocities': {},
            'temporal_coherences': {}
        }

        ref_phases = self.points.iloc[ref_point][3:].to_numpy()
        
        # Prepare data for parallel processing
        point_data = [(i, ref_phases) for i in range(len(self.points))]
        
        # Parallel processing of points
        with mp.Pool() as pool:
            results = pool.map(self._process_point, point_data)
        
        # Collect results
        for point_id, height_error, velocity, temporal_coherence in results:
            parameters['height_errors'][point_id] = height_error
            parameters['velocities'][point_id] = velocity
            parameters['temporal_coherences'][point_id] = temporal_coherence

        return parameters
```

Key improvements in this parallelized version:

1. The main point processing loop is parallelized using `multiprocessing.Pool`.
2. The coherence matrix computation is parallelized by processing each height value in parallel.
3. The code uses process-based parallelism (`multiprocessing`) rather than thread-based parallelism because of Python's Global Interpreter Lock (GIL).

Additional optimization suggestions:

1. Consider using `numpy.vectorize` or Numba's `@jit` decorator for the inner loop calculations.
2. You might want to adjust the number of processes in the pool based on your system's capabilities.
3. For very large datasets, consider using Dask or other distributed computing frameworks.
4. The search space granularity (200 points) could be adjusted based on your accuracy needs.

To use this optimized version, you would use it exactly as before, but it will automatically utilize multiple CPU cores. The number of processes will default to the number of CPU cores available on your system.

Remember that the optimal parallelization strategy might depend on:
- The size of your dataset
- The number of CPU cores available
- The amount of RAM available
- The specific characteristics of your PS points

You might need to tune the parallelization parameters (like chunk sizes and number of processes) based on your specific use case and hardware configuration.

